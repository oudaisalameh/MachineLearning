# -*- coding: utf-8 -*-
"""PLtoLenetCode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xpcGZy0aDD-3RATbAI9OlxDLuSw0KaXx
"""

!pip install pytorch_lightning

#similar
import torch
from torch import nn
from torch.nn import functional as F
import pytorch_lightning as pl
from torchvision import transforms
#different
from torch.utils.data import DataLoader, random_split
# from torchvision.datasets import CIFAR10
from torchvision.datasets import MNIST
#missing
import torchvision.datasets as datasets
import torch.optim as optim
import torch.utils.data as data
from sklearn import decomposition
from sklearn import manifold
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from tqdm.notebook import tqdm, trange
import matplotlib.pyplot as plt
import numpy as np
import copy
import random
import time

class MNISTDataModule(pl.LightningDataModule):
    def __init__(self, batch_size, data_dir: str = '.data'):
        super().__init__()
        self.data_dir = data_dir
        self.batch_size = batch_size

    def train_dataloader(self):
        train_iterator = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)
        return train_iterator

    def val_dataloader(self):
        valid_iterator = DataLoader(self.val_data, batch_size=self.batch_size)
        return valid_iterator

    def test_dataloader(self):
        test_iterator = DataLoader(self.test_dataset, batch_size=self.batch_size)
        return test_iterator

    def prepare_data(self):
        self.train_data = MNIST(self.data_dir, train=True, download=True)
        self.test_data = MNIST(self.data_dir, train=False, download=True)
        VALID_RATIO = 0.9
        self.n_train_examples = int(len(self.train_data) * VALID_RATIO)
        self.n_valid_examples = len(self.train_data) - self.n_train_examples

        mean = self.train_data.data.float().mean() / 255
        std = self.train_data.data.float().std() / 255

        self.transform = transforms.Compose([
            transforms.RandomRotation(5, fill=(0,)),
            transforms.RandomCrop(28, padding=2),
            transforms.ToTensor(),
            transforms.Normalize(mean=[mean], std=[std])
        ])

        self.train_data.transform = self.transform
        self.test_data.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[mean], std=[std])
        ])

    def setup(self, stage=None):
        if stage == 'fit' or stage is None:
            self.train_dataset, self.val_dataset = random_split(self.train_data, [self.n_train_examples, self.n_valid_examples])
            self.val_data = copy.deepcopy(self.val_dataset)
            self.val_data.dataset.transform = self.test_data.transform

        if stage == 'test' or stage is None:
            self.test_dataset = self.test_data
        print(f'Number of training examples: {len(self.train_dataset)}')
        print(f'Number of validation examples: {len(self.val_data)}')
        print(f'Number of testing examples: {len( self.test_data)}')
    @staticmethod
    def plot_filter(images, filter):
        # Convert PIL Images to PyTorch tensors
        images = torch.stack([transforms.ToTensor()(i) for i in images])

        # conactenates list of input images, unsqueeze adds new dimenson to form single tensor
        images = images.cpu()

        # converts the filter to pytorch tensor, format is compatible with PyTorch's convolution operatio
        filter = torch.FloatTensor(filter).unsqueeze(0).unsqueeze(0).cpu()

        n_images = images.shape[0]
        # applies 2D convolution to the input images using the specified filter
        # The output filtered_images will have the same shape as the input images.
        filtered_images = F.conv2d(images, filter)

        fig = plt.figure(figsize=(20, 5))
        # adds subplots to the figure for each original and filtered image pair. For each image in the batch:
        # The original image is displayed on the left side of the subplot grid.
        # The filtered image (result of convolving the original image with the filter) is displayed on the right side of the subplot grid.
        # Titles are set for each subplot, indicating whether it's the original or filtered image.
        # Axes are turned off to remove axis ticks and labels.
        for i in range(n_images):

            ax = fig.add_subplot(2, n_images, i+1)
            ax.imshow(images[i].squeeze(0), cmap='bone')
            ax.set_title('Original')
            ax.axis('off')

            image = filtered_images[i].squeeze(0)

            ax = fig.add_subplot(2, n_images, n_images+i+1)
            ax.imshow(image, cmap='bone')
            ax.set_title('Filtered')
            ax.axis('off')

    @staticmethod
    def plot_subsample(images, pool_type, pool_size):
        # Convert PIL Images to PyTorch tensors
        images = torch.stack([transforms.ToTensor()(i) for i in images])

        if pool_type.lower() == 'max':
            pool = F.max_pool2d
        elif pool_type.lower() in ['mean', 'avg']:
            pool = F.avg_pool2d
        else:
            raise ValueError(f'pool_type must be either max or mean, got: {pool_type}')

        n_images = images.shape[0]

        pooled_images = pool(images, kernel_size=pool_size)

        fig = plt.figure(figsize=(20, 5))

        for i in range(n_images):
            ax = fig.add_subplot(2, n_images, i+1)
            ax.imshow(images[i].squeeze(0), cmap='bone')
            ax.set_title('Original')
            ax.axis('off')

            image = pooled_images[i].squeeze(0)

            ax = fig.add_subplot(2, n_images, n_images+i+1)
            ax.imshow(image, cmap='bone')
            ax.set_title('Subsampled')
            ax.axis('off')

class LeNet(pl.LightningModule):
    def __init__(self, output_dim):
        super().__init__()

        self.conv1 = nn.Conv2d(in_channels=1,
                               out_channels=6,
                               kernel_size=5)

        self.conv2 = nn.Conv2d(in_channels=6,
                               out_channels=16,
                               kernel_size=5)

        self.fc_1 = nn.Linear(16 * 4 * 4, 120)
        self.fc_2 = nn.Linear(120, 84)
        self.fc_3 = nn.Linear(84, output_dim)

    def _get_conv_output(self, shape):
        batch_size = 1
        input = torch.autograd.Variable(torch.rand(batch_size, *shape))
        output_feat = self._forward_features(input)
        n_size = output_feat.data.view(batch_size, -1).size(1)
        return n_size

    # def _forward_features(self, x):
    #     x = F.relu(self.conv1(x))
    #     x = self.pool1(F.relu(self.conv2(x)))
    #     x = F.relu(self.conv3(x))
    #     x = self.pool2(F.relu(self.conv4(x)))
    #     return x

    def forward(self, x):
        # x = [batch size, 1, 28, 28]
        x = self.conv1(x)
        # x = [batch size, 6, 24, 24]
        x = F.max_pool2d(x, kernel_size=2)
        # x = [batch size, 6, 12, 12]
        x = F.relu(x)
        x = self.conv2(x)
        # x = [batch size, 16, 8, 8]
        x = F.max_pool2d(x, kernel_size=2)
        # x = [batch size, 16, 4, 4]
        x = F.relu(x)
        x = x.view(x.shape[0], -1)
        # x = [batch size, 16*4*4 = 256]
        x = self.fc_1(x)
        # x = [batch size, 120]
        x = F.relu(x)
        x = self.fc_2(x)
        # x = batch size, 84]
        x = F.relu(x)
        x = self.fc_3(x)
        # x = [batch size, output dim]
        return x

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.cross_entropy(logits, y)
        self.log('train_loss', loss)
        preds = torch.argmax(logits, dim=1)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.cross_entropy(logits, y)
        self.log('val_loss', loss)
        return loss

    def configure_optimizers(self):
        optimizer = optim.Adam(model.parameters())
        return optimizer
#different
SEED = 1234
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.backends.cudnn.deterministic = True

# Main
dm =MNISTDataModule(batch_size=64)
dm.prepare_data()
dm.setup(stage='fit')
dm.setup(stage='test')
N_IMAGES = 5
# Create a list of PIL Images instead of tensors
images = [transforms.ToPILImage()(image) for image, label in [dm.test_data[i] for i in range(N_IMAGES)]]
horizontal_filter = [[-1, -2, -1],
                    [ 0,  0,  0],
                    [ 1,  2,  1]]
dm.plot_subsample(images, 'max', 2)
dm.plot_filter(images, horizontal_filter)


OUTPUT_DIM = 10
model = LeNet(OUTPUT_DIM)
trainer = pl.Trainer(max_epochs=1)
trainer.fit(model, dm)
# trainer.test()